{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
    "Name:  Alexander Miller\n",
    "UID: U52161825\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iteration 1:**\n",
    "- Cluster 1: `[0, 0.5, 1.5]`\n",
    "- Cluster 2: `[2, 6, 6.5, 7]`\n",
    "- New Centroids: `[0.6667, 5.625]`\n",
    "\n",
    "**Iteration 2:**\n",
    "- Cluster 1: `[0, 0.5, 1.5]`\n",
    "- Cluster 2: `[2, 6, 6.5, 7]`\n",
    "- New Centroids: `[0.6667, 5.625]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-means cost function measures how spread out data points are from the centers of their assigned clusters. It aims to minimize the sum of squared distances between each point and its cluster center, ensuring tight and compact clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means results can vary due to sensitivity to initial centroid positions, different data distributions, and potential convergence to local minima. Outliers and noise can also impact outcomes. Running the algorithm multiple times with various initializations helps mitigate these variations.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, Lloyd's Algorithm always converges. It iteratively reduces the sum of squared distances between data points and centroids, ensuring a finite number of steps. However, it may converge to a local minimum, prompting the use of multiple runs with varied initializations to enhance the chances of finding an optimal solution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/f2/b4/c273b046e0f14e76ec33fdce82d70ddce1c796aaabadf436b3b8bf01ffb5/scikit_learn-1.3.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/alexmiller/Library/Python/3.11/lib/python/site-packages (from scikit-learn) (1.25.2)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Obtaining dependency information for scipy>=1.5.0 from https://files.pythonhosted.org/packages/b1/a6/b6d66d4f4045ba59200d25f254ccd63340162c903f95231e3ae6863fc4ae/scipy-1.11.3-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading scipy-1.11.3-cp311-cp311-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.1-cp311-cp311-macosx_10_9_x86_64.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading scipy-1.11.3-cp311-cp311-macosx_10_9_x86_64.whl (37.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.2/37.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.1 scipy-1.11.3 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    def snap(self, centers):\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "\n",
    "\n",
    "    def lloyds(self):\n",
    "            # Initialize centroids\n",
    "            centers = self.data[np.random.choice(len(self.data), self.k, replace=False)]\n",
    "            \n",
    "            while True:\n",
    "                # Assignment step\n",
    "                distances = np.linalg.norm(self.data[:, None, :] - centers, axis=2)\n",
    "                new_assignment = np.argmin(distances, axis=1)\n",
    "                \n",
    "                # Check for convergence\n",
    "                if np.array_equal(self.assignment, new_assignment):\n",
    "                    break\n",
    "                \n",
    "                # Update step\n",
    "                for i in range(self.k):\n",
    "                    if np.any(new_assignment == i):\n",
    "                        centers[i] = np.mean(self.data[new_assignment == i], axis=0)\n",
    "                \n",
    "                # Update assignments and create snapshot\n",
    "                self.assignment = new_assignment\n",
    "                self.snap(centers)\n",
    "\n",
    "            return\n",
    "            \n",
    "\n",
    "kmeans = KMeans(X, 6)\n",
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
